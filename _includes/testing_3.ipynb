{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b68d579-ad6f-4528-9b49-c9164343e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sp\n",
    "import sys\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_TEMPLATE = (\n",
    "    \"Initial t-test p-value (invalid):\\t\\t{initial_ttest_p:.3g}\\n\"\n",
    "    \"Normality p-value of original data:\\t\\t{initial_weekday_normality_p:.3g}, {initial_weekend_normality_p:.3g}\\n\"\n",
    "    \"Equal variance p-value of original data:\\t\\t{initial_levene_p:.3g}\\n\"\n",
    "    \"Normality p-value of transformed data:\\t\\t{transformed_weekday_normality_p:.3g}, {transformed_weekend_normality_p:.3g}\\n\"\n",
    "    \"Equal variance p-value of transformed data:\\t{transformed_levene_p:.3g}\\n\"\n",
    "    \"Normality p-value of weekly data:\\t\\t\\t{weekly_weekday_normality_p:.3g}, {weekly_weekend_normality_p:.3g}\\n\"\n",
    "    \"Equal variance p-value of weekly data:\\t\\t{weekly_levene_p:.3g}\\n\"\n",
    "    \"Weekly t-test p-value:\\t\\t\\t\\t{weekly_ttest_p:.3g}\\n\"\n",
    "    \"Mann–Whitney U test p-value:\\t\\t\\t{utest_p:.3g}\"\n",
    ")\n",
    "\n",
    "\n",
    "def read_data(path: str) -> pd.DataFrame:\n",
    "    # do not modify\n",
    "    return pd.read_json(path, lines=True) \n",
    "\n",
    "\n",
    "def split_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # do not modify\n",
    "    wd = df.query(\"is_weekend==False\")\n",
    "    we = df.query(\"is_weekend==True\")\n",
    "    return wd, we\n",
    "\n",
    "\n",
    "def draw_histogram(df: pd.DataFrame, title: str = None) -> Figure:\n",
    "    # do not modify\n",
    "    fig, ax = plt.subplots(1, 1, dpi=100)\n",
    "    ret = sns.histplot(data=df, x='comment_count', hue='is_weekend', ax=ax)\n",
    "    if title:\n",
    "        ret.set(title=title)\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0bf9b3-2cca-4098-b70c-07e76d6f66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/antonioslagarias/IFT6758/hw3-en/data/reddit-counts.json.gz\"\n",
    "#if len(sys.argv) > 1:\n",
    "#    path = sys.argv[1]\n",
    "\n",
    "# load data\n",
    "raw_df = read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f9f6eb-c9a1-46b2-b51c-e397c7fec0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-02-20</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-15</td>\n",
       "      <td>saskatchewan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-06</td>\n",
       "      <td>canada</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>2012-05-21</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15466</th>\n",
       "      <td>2012-05-21</td>\n",
       "      <td>britishcolumbia</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15467</th>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>britishcolumbia</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15468</th>\n",
       "      <td>2011-09-10</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15469</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>canada</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15470 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        subreddit  comment_count\n",
       "0     2012-02-20     newfoundland              7\n",
       "1     2015-01-26         Manitoba              1\n",
       "2     2013-09-07            Yukon              2\n",
       "3     2014-02-15     saskatchewan              5\n",
       "4     2014-07-06           canada           1652\n",
       "...          ...              ...            ...\n",
       "15465 2012-05-21           Quebec            365\n",
       "15466 2012-05-21  britishcolumbia              4\n",
       "15467 2013-09-07  britishcolumbia              5\n",
       "15468 2011-09-10           Quebec              2\n",
       "15469 2012-01-02           canada           1127\n",
       "\n",
       "[15470 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e99b174-3ebe-4af3-83a6-c9997a1da539",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Timestamp' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\n\u001b[32m      3\u001b[39m raw_df[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m].year\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mraw_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m.year\n",
      "\u001b[31mAttributeError\u001b[39m: 'Timestamp' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "raw_df[\"date\"][0].year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168d13-6b4a-40b9-ba3f-294c788bbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7098eb0e-e674-4761-9e6d-5d8cc54d4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Complete this method\n",
    "def process_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the raw DataFrame:\n",
    "\n",
    "    1. Keep only the 'Canada' subreddit\n",
    "    2. Keep only the years 2012 and 2013\n",
    "    3. Add a new column 'is_weekend' with a Boolean value of True/False\n",
    "\n",
    "    Args:\n",
    "    df(pd.DataFrame): Dataframe to process; contains the columns\n",
    "    'date', 'subreddit', 'comment_count' by default\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Must have at least the columns: 'comment_count', 'date', 'is_weekend'\n",
    "    \"\"\"\n",
    "    df = df.copy()  #copy so that you don't modify the original dataframe\n",
    "    df = df[df['subreddit'] == \"canada\"]\n",
    "    \n",
    "    df = df[df['date'].dt.year.isin([2012, 2013])]\n",
    "    df['is_weekend'] = df['date'].dt.weekday.isin([5,6])\n",
    "    # TODO: Filtrez sur years, subreddit, et ajoutez une colonne boolean 'is_weekend' \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e94f697-549b-4ae6-97d9-61bae48ccc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-02-20</td>\n",
       "      <td>newfoundland</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-15</td>\n",
       "      <td>saskatchewan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-06</td>\n",
       "      <td>canada</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>2012-05-21</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15466</th>\n",
       "      <td>2012-05-21</td>\n",
       "      <td>britishcolumbia</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15467</th>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>britishcolumbia</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15468</th>\n",
       "      <td>2011-09-10</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15469</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>canada</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15470 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        subreddit  comment_count\n",
       "0     2012-02-20     newfoundland              7\n",
       "1     2015-01-26         Manitoba              1\n",
       "2     2013-09-07            Yukon              2\n",
       "3     2014-02-15     saskatchewan              5\n",
       "4     2014-07-06           canada           1652\n",
       "...          ...              ...            ...\n",
       "15465 2012-05-21           Quebec            365\n",
       "15466 2012-05-21  britishcolumbia              4\n",
       "15467 2013-09-07  britishcolumbia              5\n",
       "15468 2011-09-10           Quebec              2\n",
       "15469 2012-01-02           canada           1127\n",
       "\n",
       "[15470 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "445482a1-0bf7-4469-baed-19c0a8d760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=other[other[\"weekend\"]==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "846f6732-1679-4549-92b9-d7a5084ac718",
   "metadata": {},
   "outputs": [],
   "source": [
    "we=other[other[\"weekend\"]==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1035f95-695d-45f1-b9aa-30453d00eeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.3005502847208094e-58)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.ttest_ind(wd[\"comment_count\"], we[\"comment_count\"]).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21ac7615-9d18-491d-a7f3-cef4bdd9bb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormaltestResult(statistic=np.float64(32.21804641032879), pvalue=np.float64(1.0091137251707994e-07))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.normaltest(wd[\"comment_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "741d40f0-5ff9-4618-b501-c6e253c33e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.06604578026604031)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.fligner(wd[\"comment_count\"], we[\"comment_count\"]).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f38e8bde-033c-4f2e-88ea-e35a80e79967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Complétez cette méthode\n",
    "def tests(wd: pd.DataFrame, we: pd.DataFrame, verbose: bool = False) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Performs a t-test between the two inputs, checking whether the mean of the two distributions is\n",
    "    the same. It also checks whether the two input data sets have a normal distribution and the\n",
    "    same variance (a requirement for the t-test).\n",
    "\n",
    "    Reference: https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests\n",
    "\n",
    "    Arguments:\n",
    "    wd (pd.DataFrame): weekday data\n",
    "    we (pd.DataFrame): weekend data\n",
    "    verbose (bool): Whether to display the results\n",
    "\n",
    "    Returns:\n",
    "    Tuple[float, float, float, float]: p_test, p_wd_isnormal, p_we_isnormal, p_vartest\n",
    "    \"\"\"\n",
    "    p_ttest, p_wd_normal, p_we_normal, p_vartest = None, None, None, None\n",
    "\n",
    "    p_ttest=sp.ttest_ind(wd[\"comment_count\"], we[\"comment_count\"]).pvalue\n",
    "    p_wd_normal=sp.normaltest(wd[\"comment_count\"]).pvalue\n",
    "    p_we_normal=sp.normaltest(we[\"comment_count\"]).pvalue\n",
    "    p_vartest=sp.fligner(wd[\"comment_count\"], we[\"comment_count\"]).pvalue\n",
    "    \n",
    "    # TODO: Get the p-value for the t-test\n",
    "\n",
    "    # TODO: Get the p-value for the normality test on the weekday and weekend data separately\n",
    "    # That is, are both distributions normal?\n",
    "\n",
    "    # TODO: Get the p-value for the test that checks whether these two distributions have the same variance\n",
    "    # ---------- DO NOT CHANGE THE FUNCTION BELOW THIS LINE ---------- #\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"p_value:\\t{p_ttest.round(5)}\")\n",
    "        print(f\"WD normality:\\t{p_wd_normal.round(5)}\")\n",
    "        print(f\"WE normality:\\t{p_we_normal.round(5)}\")\n",
    "        print(f\"Variance test:\\t{p_vartest.round(5)}\")\n",
    "\n",
    "    return p_ttest, p_wd_normal, p_we_normal, p_vartest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88bf4287-24b5-4913-826c-fba5e650fbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value:\t0.0\n",
      "WD normality:\t0.0\n",
      "WE normality:\t0.00152\n",
      "Variance test:\t0.06605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(1.3005502847208094e-58),\n",
       " np.float64(1.0091137251707994e-07),\n",
       " np.float64(0.0015209196859635404),\n",
       " np.float64(0.06604578026604031))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests(wd,we,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fea45e-891d-48ec-af33-2f0d9c586802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Complete this mewthod\n",
    "def central_limit_theorem(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine all weekdays and weekends for each year/week pair and take the average of their\n",
    "    (untransformed) counts.\n",
    "\n",
    "    Tip: You can get a \"year\" and a \"week number\" from the first two values ​​returned\n",
    "    by date.isocalendar(). This year and week number will give you an identifier for the (year, week) pair.\n",
    "    Use Pandas to group by this value and aggregate by taking the average.\n",
    "\n",
    "    Note: The year returned by isocalendar is not always the same as the year of the date (around New\n",
    "    Year's Day). Use the year from the isocalendar, which is correct in this case. This is different from the\n",
    "    year you used to filter events; do not perform any additional filtering!\n",
    "\n",
    "    Arguments:\n",
    "    df(pd.DataFrame): Cleaned dataframe containing (at least) the columns: 'date', 'comment_count', 'is_weekend'\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Must have (at least) the columns: 'comment_count', 'is_weekend'\n",
    "     \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # TODO: Combine all weekdays and weekends of each year/week pair and take the average of their (untransformed) counts.\n",
    "    clt: pd.DataFrame = None \n",
    "\n",
    "    \n",
    "    return clt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
